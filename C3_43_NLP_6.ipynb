{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg9yd6CxjfQ8"
      },
      "source": [
        "Name : Kamaleshwar Viyanwar\n",
        "\n",
        "Roll no: C3-43\n",
        "\n",
        "Practical-7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbCFTPXfUPtL",
        "outputId": "58a13884-e2a9-4962-a959-cbdea4dfb583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fX8SDNLUlWV",
        "outputId": "a726d6b4-b2d9-495f-bf69-53943f7420bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUf3ZQljXbR1"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import collections\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30gcNRUHVBUd"
      },
      "outputs": [],
      "source": [
        "text = \"Give papa a cup of proper coffee in a copper coffee mug.\"\n",
        "tokens = word_tokenize(text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnX6HT2IVRNT",
        "outputId": "9bf5885c-9c0e-4e32-8641-f5a87a5e61b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bigrams: [('give', 'papa'), ('papa', 'a'), ('a', 'cup'), ('cup', 'of'), ('of', 'proper'), ('proper', 'coffee'), ('coffee', 'in'), ('in', 'a'), ('a', 'copper'), ('copper', 'coffee'), ('coffee', 'mug'), ('mug', '.')]\n"
          ]
        }
      ],
      "source": [
        "# Generate bigrams\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "print(\"Bigrams:\", bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra0-ZfJPVfVE",
        "outputId": "3ee1ec07-226e-400f-cd15-6252f4a3db74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trigrams: [('give', 'papa', 'a'), ('papa', 'a', 'cup'), ('a', 'cup', 'of'), ('cup', 'of', 'proper'), ('of', 'proper', 'coffee'), ('proper', 'coffee', 'in'), ('coffee', 'in', 'a'), ('in', 'a', 'copper'), ('a', 'copper', 'coffee'), ('copper', 'coffee', 'mug'), ('coffee', 'mug', '.')]\n"
          ]
        }
      ],
      "source": [
        "# Generate trigrams\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "print(\"Trigrams:\", trigrams)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5qm5b2JXk0M"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert to lowercase and remove non-alphabetic characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
        "    words = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return filtered_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMsvyi4wXw3M"
      },
      "outputs": [],
      "source": [
        "def generate_ngrams(words, n):\n",
        "    return list(ngrams(words, n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHW1g7uUX1e8"
      },
      "outputs": [],
      "source": [
        "def get_ngram_frequencies(ngrams_list):\n",
        "    return collections.Counter(ngrams_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBWkpyA1X4_l"
      },
      "outputs": [],
      "source": [
        "def laplace_smoothing(ngram_freqs, vocab_size, total_ngrams, ngram):\n",
        "    ngram_count = ngram_freqs[ngram] if ngram in ngram_freqs else 0\n",
        "    return (ngram_count + 1) / (total_ngrams + vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt67TRpZX8B8"
      },
      "outputs": [],
      "source": [
        "def good_turing_discounting(ngram_freqs, total_ngrams, ngram, ngram_count):\n",
        "    count_of_n_count = sum(1 for count in ngram_freqs.values() if count == ngram_count)\n",
        "    if ngram_count == 0:\n",
        "        return count_of_n_count / total_ngrams\n",
        "    else:\n",
        "        return (ngram_count + 1) * (count_of_n_count + 1) / (total_ngrams * count_of_n_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAhWN_W4VjX7"
      },
      "outputs": [],
      "source": [
        "class BackOffModel:\n",
        "    def __init__(self, ngram_freqs, vocab_size, total_ngrams, smoothing_func):\n",
        "        self.ngram_freqs = ngram_freqs\n",
        "        self.vocab_size = vocab_size\n",
        "        self.total_ngrams = total_ngrams\n",
        "        self.smoothing_func = smoothing_func\n",
        "        self.cache = {}\n",
        "\n",
        "    def get_probability(self, ngram):\n",
        "        if ngram in self.cache:\n",
        "            return self.cache[ngram]\n",
        "\n",
        "        ngram_count = self.ngram_freqs[ngram] if ngram in self.ngram_freqs else 0\n",
        "        probability = self.smoothing_func(self.ngram_freqs, self.vocab_size, self.total_ngrams, ngram)\n",
        "        self.cache[ngram] = probability\n",
        "        return probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ6QVNmjV7wU"
      },
      "outputs": [],
      "source": [
        "words=preprocess_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eywfVMiWNtb",
        "outputId": "5eec8ed7-edee-4309-bd31-7e3074c9535c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('give',),\n",
              " ('papa',),\n",
              " ('cup',),\n",
              " ('proper',),\n",
              " ('coffee',),\n",
              " ('copper',),\n",
              " ('coffee',),\n",
              " ('mug',)]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#unigrams\n",
        "n = 1\n",
        "ngrams_list = generate_ngrams(words, n)\n",
        "ngrams_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SIuaTs2Y_gM",
        "outputId": "9ee2c92c-21af-4597-d26b-9bb98a614663"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('give', 'papa'),\n",
              " ('papa', 'cup'),\n",
              " ('cup', 'proper'),\n",
              " ('proper', 'coffee'),\n",
              " ('coffee', 'copper'),\n",
              " ('copper', 'coffee'),\n",
              " ('coffee', 'mug')]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n = 2\n",
        "bigrams_list = generate_ngrams(words, n)\n",
        "bigrams_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0yqFCr9ZVJc",
        "outputId": "dd328314-be63-4364-b365-9ef35c08019f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('give', 'papa', 'cup'),\n",
              " ('papa', 'cup', 'proper'),\n",
              " ('cup', 'proper', 'coffee'),\n",
              " ('proper', 'coffee', 'copper'),\n",
              " ('coffee', 'copper', 'coffee'),\n",
              " ('copper', 'coffee', 'mug')]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n = 3\n",
        "trigrams_list = generate_ngrams(words, n)\n",
        "trigrams_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unJq7n26WdeM",
        "outputId": "6d72c394-e470-421c-c8bf-426c24718837"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_freqs = get_ngram_frequencies(bigrams_list)\n",
        "total_bigrams = sum(bigram_freqs.values())\n",
        "vocab_size = len(set(words))\n",
        "total_bigrams\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyIgsEWCaHkt",
        "outputId": "192c48d3-5097-466b-d3be-47f6869095f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({('give', 'papa'): 1,\n",
              "         ('papa', 'cup'): 1,\n",
              "         ('cup', 'proper'): 1,\n",
              "         ('proper', 'coffee'): 1,\n",
              "         ('coffee', 'copper'): 1,\n",
              "         ('copper', 'coffee'): 1,\n",
              "         ('coffee', 'mug'): 1})"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDuIq9omYV0k",
        "outputId": "eac28e06-c691-4dbd-e41c-d9090d278845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4PkY63TZym8",
        "outputId": "300467f4-66d0-4c41-b4b9-1beb699faf76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Laplace smoothed probability for ('give', 'papa'): 0.1429\n",
            "Laplace smoothed probability for ('papa', 'cup'): 0.1429\n",
            "Laplace smoothed probability for ('cup', 'proper'): 0.1429\n",
            "Laplace smoothed probability for ('proper', 'coffee'): 0.1429\n",
            "Laplace smoothed probability for ('coffee', 'copper'): 0.1429\n",
            "Laplace smoothed probability for ('copper', 'coffee'): 0.1429\n",
            "Laplace smoothed probability for ('coffee', 'mug'): 0.1429\n"
          ]
        }
      ],
      "source": [
        "for bigram in bigrams_list:\n",
        "    prob = laplace_smoothing(bigram_freqs, vocab_size, total_bigrams, bigram)\n",
        "    print(f\"Laplace smoothed probability for {bigram}: {prob:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73z7DBquahDE",
        "outputId": "1c867bf0-ab91-444e-d3e4-ebbf25eb5c77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Good-Turing discounting for ('give', 'papa'): 0.3265\n",
            "Good-Turing discounting for ('papa', 'cup'): 0.3265\n",
            "Good-Turing discounting for ('cup', 'proper'): 0.3265\n",
            "Good-Turing discounting for ('proper', 'coffee'): 0.3265\n",
            "Good-Turing discounting for ('coffee', 'copper'): 0.3265\n",
            "Good-Turing discounting for ('copper', 'coffee'): 0.3265\n",
            "Good-Turing discounting for ('coffee', 'mug'): 0.3265\n"
          ]
        }
      ],
      "source": [
        "# Apply Good-Turing discounting\n",
        "for bigram in bigrams_list:\n",
        "    prob = good_turing_discounting(bigram_freqs, total_bigrams, bigram, 1)\n",
        "    print(f\"Good-Turing discounting for {bigram}: {prob:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUtXwOFOapuc",
        "outputId": "d2600b1e-8f04-4ee0-b8f0-8bf2d794e781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Back-Off Model for ('give', 'papa'): 0.1429\n",
            "Back-Off Model for ('papa', 'cup'): 0.1429\n",
            "Back-Off Model for ('cup', 'proper'): 0.1429\n",
            "Back-Off Model for ('proper', 'coffee'): 0.1429\n",
            "Back-Off Model for ('coffee', 'copper'): 0.1429\n",
            "Back-Off Model for ('copper', 'coffee'): 0.1429\n",
            "Back-Off Model for ('coffee', 'mug'): 0.1429\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Back-Off Model\n",
        "backoff_model = BackOffModel(bigram_freqs, vocab_size, total_bigrams, laplace_smoothing)\n",
        "\n",
        "# Apply Back-Off Model\n",
        "for bigram in bigrams_list:\n",
        "    prob = backoff_model.get_probability(bigram)\n",
        "    print(f\"Back-Off Model for {bigram}: {prob:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efwiCdYViSFl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
